{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering Development\n",
    "\n",
    "This notebook is used for the development of new features and transformers. Once development on a transformer is complete it will be saved as a new file in `src/prep/`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Target variable creation\n",
    "\n",
    "Currently, the dataset has no suitable target variables, so they will have to be created. There a multiple directions this could take, however for v1 it the target will be binary, with the following rules:\n",
    "\n",
    "if: Open > Close then 1\n",
    "else: 0\n",
    "\n",
    "This column will then need to be shifted up the dataset one row.\n",
    "\n",
    "Since the datasets have less than 50k rows computing this in numpy is more efficient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing ibm_historcial.csv to serve as test for development\n",
    "ibm = pd.read_csv('../data/ibm_historical.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                        Date       Open       High        Low      Close  \\\n0  2000-01-03 00:00:00-05:00  62.830047  64.820770  62.515725  64.820770   \n1  2000-01-04 00:00:00-05:00  63.703158  63.982558  61.956909  62.620483   \n2  2000-01-05 00:00:00-05:00  63.109447  66.916272  62.655425  64.820770   \n3  2000-01-06 00:00:00-05:00  65.938384  66.462258  63.423786  63.703186   \n4  2000-01-07 00:00:00-05:00  65.519260  65.903434  61.817214  63.423763   \n\n     Volume  Dividends  Stock Splits  \n0  10823694        0.0           0.0  \n1   8606279        0.0           0.0  \n2  13318927        0.0           0.0  \n3   8338607        0.0           0.0  \n4  12402108        0.0           0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Dividends</th>\n      <th>Stock Splits</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000-01-03 00:00:00-05:00</td>\n      <td>62.830047</td>\n      <td>64.820770</td>\n      <td>62.515725</td>\n      <td>64.820770</td>\n      <td>10823694</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2000-01-04 00:00:00-05:00</td>\n      <td>63.703158</td>\n      <td>63.982558</td>\n      <td>61.956909</td>\n      <td>62.620483</td>\n      <td>8606279</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000-01-05 00:00:00-05:00</td>\n      <td>63.109447</td>\n      <td>66.916272</td>\n      <td>62.655425</td>\n      <td>64.820770</td>\n      <td>13318927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2000-01-06 00:00:00-05:00</td>\n      <td>65.938384</td>\n      <td>66.462258</td>\n      <td>63.423786</td>\n      <td>63.703186</td>\n      <td>8338607</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000-01-07 00:00:00-05:00</td>\n      <td>65.519260</td>\n      <td>65.903434</td>\n      <td>61.817214</td>\n      <td>63.423763</td>\n      <td>12402108</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.0\n1    1.0\n2    0.0\n3    1.0\n4    1.0\ndtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing inequality\n",
    "(ibm['Open'] > ibm['Close']).astype(float)[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.0\n1    1.0\n2    0.0\n3    0.0\n4    1.0\nName: target, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm['target'] = (ibm['Open'] < ibm['Close']).astype(float).shift(-1)\n",
    "\n",
    "ibm['target'][:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calculateTarget(df):\n",
    "    df['target'] = (df['Open'] < df['Close']).astype(float).shift(-1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(        Open      Close  target\n 0  62.830047  64.820770     0.0\n 1  63.703158  62.620483     1.0\n 2  63.109447  64.820770     0.0\n 3  65.938384  63.703186     0.0\n 4  65.519260  63.423763     1.0,\n             Open       Close  target\n 5721  121.650002  122.760002     0.0\n 5722  121.849998  121.629997     0.0\n 5723  121.660004  118.809998     1.0\n 5724  120.160004  121.510002     1.0\n 5725  122.800003  125.500000     NaN)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function operates as intended\n",
    "ibm = pd.read_csv('../data/ibm_historical.csv')\n",
    "\n",
    "calculateTarget(ibm)\n",
    "\n",
    "ibm[['Open', 'Close', 'target']][:5], ibm[['Open', 'Close', 'target']][-5:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Package into python file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/dataPreparation/createTarget.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/dataPreparation/createTarget.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculateTarget(df):\n",
    "    \"\"\"\n",
    "    Calculates target variable from a pandas dataframe, does this in an inplace fashion.\n",
    "    Dataframe MUST contain columns 'Open' and 'Close'.\n",
    "    :param df:\n",
    "    \"\"\"\n",
    "    df['target'] = (df['Open'] < df['Close']).astype(float).shift(-1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non Temporal CNN data preparation\n",
    "\n",
    "This approach involves consoladating a specific window of data from the dataset into a matrix, which is exactly the same format an image would be propergated through a neural network.\n",
    "\n",
    "This will require function to be created that 'packages' the data into the matrices.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import src.dataPreparation as prep\n",
    "\n",
    "# Import data for development\n",
    "msft = pd.read_csv('../data/msft_historical.csv', delimiter=',')\n",
    "\n",
    "# Remove Date from dataframe since it is not required anymore\n",
    "msft.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Calculate target variable\n",
    "msft = prep.calculateTarget(msft)\n",
    "\n",
    "# Separate x and y\n",
    "X, y = msft.drop(columns='target'), msft.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 21:00:48.006472: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-10 21:00:48.006595: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas dataframe to tensorflow tensor to improve computational speed\n",
    "X_tensor = tf.convert_to_tensor(X)\n",
    "y_tensor = tf.convert_to_tensor(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Creating the first packet of data for window size of 5\n",
    "first_packet_x = X_tensor[:5]\n",
    "first_packet_y = y_tensor[5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(5, 7), dtype=float64, numpy=\n array([[3.68101952e+01, 3.72022101e+01, 3.51245314e+01, 3.65553856e+01,\n         5.32284000e+07, 0.00000000e+00, 0.00000000e+00],\n        [3.56145333e+01, 3.67317751e+01, 3.52029179e+01, 3.53205223e+01,\n         5.41190000e+07, 0.00000000e+00, 0.00000000e+00],\n        [3.48501156e+01, 3.64965777e+01, 3.43012949e+01, 3.56929474e+01,\n         6.40596000e+07, 0.00000000e+00, 0.00000000e+00],\n        [3.51833250e+01, 3.57125450e+01, 3.39876800e+01, 3.44972992e+01,\n         5.49766000e+07, 0.00000000e+00, 0.00000000e+00],\n        [3.40660831e+01, 3.52029259e+01, 3.36544676e+01, 3.49481163e+01,\n         6.20136000e+07, 0.00000000e+00, 0.00000000e+00]])>,\n <tf.Tensor: shape=(), dtype=float64, numpy=0.0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_packet_x, first_packet_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([5726, 7]), TensorShape([5726]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tensor shapes\n",
    "X_tensor.shape, y_tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([5721, 5, 7]), TensorShape([5721]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for tensors\n",
    "X_tensor_stack = []\n",
    "\n",
    "# Create loop logic to create packets for a window size of 5\n",
    "for i, _ in enumerate(X_tensor[:-1]):\n",
    "    i += 5\n",
    "\n",
    "    packet = X_tensor[:-1][i-5:i]\n",
    "    X_tensor_stack.append(packet)\n",
    "\n",
    "# Turn stack into one tensor\n",
    "X_tensor_reshape = tf.stack(X_tensor_stack[:-4])\n",
    "\n",
    "# Find target values\n",
    "y_tensor_reshape = y_tensor[5:]\n",
    "\n",
    "X_tensor_reshape.shape, y_tensor_reshape.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def nonTemporalTransform(X, y, window_size):\n",
    "    # Convert to tensor format\n",
    "    X_tensor = tf.convert_to_tensor(X)\n",
    "    y_tensor = tf.convert_to_tensor(y)\n",
    "\n",
    "    # Create list for stack\n",
    "    X_tensor_stack = []\n",
    "\n",
    "    # Package loop\n",
    "    for i, _ in enumerate(X_tensor):\n",
    "        i += window_size\n",
    "\n",
    "        packet = X_tensor[:-1][i-window_size:i]\n",
    "        X_tensor_stack.append(packet)\n",
    "\n",
    "    # Convert stack into one tensor\n",
    "    X_reshape = tf.stack(X_tensor_stack[:-(window_size-1)])\n",
    "\n",
    "    # Find target values\n",
    "    y_reshape = y_tensor[window_size:]\n",
    "\n",
    "    return X_reshape, y_reshape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Package into python file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/dataPreparation/nonTemporalWindowFunction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/dataPreparation/nonTemporalWindowFunction.py\n",
    "# Import requried libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def nonTemporalTransform(X, y, window_size):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X: X values in pandas dataframe format\n",
    "    :param y: y values in pandas dataframe format\n",
    "    :param window_size: size of prediction window\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Convert to tensor format\n",
    "    X_tensor = tf.convert_to_tensor(X)\n",
    "    y_tensor = tf.convert_to_tensor(y)\n",
    "\n",
    "    # Create list for stack\n",
    "    X_tensor_stack = []\n",
    "\n",
    "    # Package loop\n",
    "    for i, _ in enumerate(X_tensor):\n",
    "        i += window_size\n",
    "\n",
    "        packet = X_tensor[:-1][i-window_size:i]\n",
    "        X_tensor_stack.append(packet)\n",
    "\n",
    "    # Convert stack into one tensor\n",
    "    X_reshape = tf.stack(X_tensor_stack[:len(X_tensor_stack)-window_size])\n",
    "\n",
    "    # Find target values\n",
    "    y_reshape = y_tensor[window_size:]\n",
    "\n",
    "    return X_reshape, y_reshape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor normalizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 13:00:01.695073: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-01 13:00:01.695620: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.dataPreparation as prep\n",
    "\n",
    "# Import nvda_historical.csv for dev\n",
    "nvda = pd.read_csv('../data/nvda_historical.csv')\n",
    "\n",
    "# Create fake y_tensor\n",
    "fake_y = tf.random.uniform(shape=(1, len(nvda)))\n",
    "\n",
    "# Transform data into windowed format\n",
    "window = 5\n",
    "\n",
    "nvda, fake_y = prep.nonTemporalTransform(\n",
    "    nvda.drop(columns=['Date']),\n",
    "    fake_y,\n",
    "    window_size=window\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(5722, 5, 4), dtype=float64, numpy=\n array([[[  0.90364332,   0.91081553,   0.8438787 ,   0.89527589],\n         [  0.87973735,   0.88212867,   0.82714492,   0.87137079],\n         [  0.8462694 ,   0.86061295,   0.83073063,   0.84268373],\n         [  0.84268362,   0.84268362,   0.75542712,   0.78769988],\n         [  0.78411425,   0.8092148 ,   0.77216115,   0.80084825]],\n \n        [[  0.87973735,   0.88212867,   0.82714492,   0.87137079],\n         [  0.8462694 ,   0.86061295,   0.83073063,   0.84268373],\n         [  0.84268362,   0.84268362,   0.75542712,   0.78769988],\n         [  0.78411425,   0.8092148 ,   0.77216115,   0.80084825],\n         [  0.80323871,   0.86061291,   0.78889517,   0.82714492]],\n \n        [[  0.8462694 ,   0.86061295,   0.83073063,   0.84268373],\n         [  0.84268362,   0.84268362,   0.75542712,   0.78769988],\n         [  0.78411425,   0.8092148 ,   0.77216115,   0.80084825],\n         [  0.80323871,   0.86061291,   0.78889517,   0.82714492],\n         [  0.82236311,   0.83192577,   0.79367602,   0.79367602]],\n \n        ...,\n \n        [[124.19999695, 126.11000061, 122.56999969, 125.16000366],\n         [124.91000366, 126.58999634, 122.13999939, 122.27999878],\n         [125.06999969, 127.36000061, 122.58000183, 124.12999725],\n         [124.09999847, 128.22999573, 123.54000092, 127.36000061],\n         [124.48000336, 125.        , 119.45999908, 122.19999695]],\n \n        [[124.91000366, 126.58999634, 122.13999939, 122.27999878],\n         [125.06999969, 127.36000061, 122.58000183, 124.12999725],\n         [124.09999847, 128.22999573, 123.54000092, 127.36000061],\n         [124.48000336, 125.        , 119.45999908, 122.19999695],\n         [120.87000275, 126.33000183, 120.75      , 121.38999939]],\n \n        [[125.06999969, 127.36000061, 122.58000183, 124.12999725],\n         [124.09999847, 128.22999573, 123.54000092, 127.36000061],\n         [124.48000336, 125.        , 119.45999908, 122.19999695],\n         [120.87000275, 126.33000183, 120.75      , 121.38999939],\n         [123.47000122, 126.77999878, 121.05000305, 125.12000275]]])>,\n <tf.Tensor: shape=(5722, 5), dtype=float64, numpy=\n array([[30091200., 30048000., 18835200., 12048000.,  7118400.],\n        [30048000., 18835200., 12048000.,  7118400., 23985600.],\n        [18835200., 12048000.,  7118400., 23985600., 14812800.],\n        ...,\n        [66184000., 54734300., 55385400., 54241400., 53276300.],\n        [54734300., 55385400., 54241400., 53276300., 56486900.],\n        [55385400., 54241400., 53276300., 56486900., 54747800.]])>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test subseting data correctly\n",
    "nvda[:, :, :4], nvda[:, :, 4]  # Candlestick features and Volume respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5722, 5, 4), dtype=float64, numpy=\narray([[[0.50835466, 0.51238947, 0.4747334 , 0.50364747],\n        [0.50829418, 0.50967584, 0.47790736, 0.50346015],\n        [0.50066736, 0.50915324, 0.49147436, 0.49854601],\n        [0.52147096, 0.52147096, 0.46747474, 0.48744583],\n        [0.49519943, 0.51105143, 0.48765057, 0.50576762]],\n\n       [[0.50829418, 0.50967584, 0.47790736, 0.50346015],\n        [0.50066736, 0.50915324, 0.49147436, 0.49854601],\n        [0.52147096, 0.52147096, 0.46747474, 0.48744583],\n        [0.49519943, 0.51105143, 0.48765057, 0.50576762],\n        [0.48952757, 0.52449382, 0.48078601, 0.50409702]],\n\n       [[0.50066736, 0.50915324, 0.49147436, 0.49854601],\n        [0.52147096, 0.52147096, 0.46747474, 0.48744583],\n        [0.49519943, 0.51105143, 0.48765057, 0.50576762],\n        [0.48952757, 0.52449382, 0.48078601, 0.50409702],\n        [0.50726204, 0.51316062, 0.48956685, 0.48956685]],\n\n       ...,\n\n       [[0.49872759, 0.50639725, 0.49218231, 0.50258252],\n        [0.50369347, 0.51046796, 0.49252357, 0.49308811],\n        [0.50109368, 0.51026859, 0.49111749, 0.49732756],\n        [0.49315022, 0.50956206, 0.49092489, 0.50610486],\n        [0.50682174, 0.50893892, 0.48638274, 0.49753867]],\n\n       [[0.50369347, 0.51046796, 0.49252357, 0.49308811],\n        [0.50109368, 0.51026859, 0.49111749, 0.49732756],\n        [0.49315022, 0.50956206, 0.49092489, 0.50610486],\n        [0.50682174, 0.50893892, 0.48638274, 0.49753867],\n        [0.49392361, 0.51623537, 0.49343323, 0.49604853]],\n\n       [[0.50109368, 0.51026859, 0.49111749, 0.49732756],\n        [0.49315022, 0.50956206, 0.49092489, 0.50610486],\n        [0.50682174, 0.50893892, 0.48638274, 0.49753867],\n        [0.49392361, 0.51623537, 0.49343323, 0.49604853],\n        [0.49736934, 0.51070288, 0.48762096, 0.50401598]]])>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Normalizing candlestick features\n",
    "tf.linalg.normalize(nvda[:, :, :4], axis=2)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5722, 5), dtype=float64, numpy=\narray([[0.61955496, 0.6186655 , 0.38780246, 0.24805917, 0.14656245],\n       [0.66711066, 0.41816968, 0.26748367, 0.15803915, 0.53251629],\n       [0.51352033, 0.32847503, 0.19407509, 0.65394013, 0.40385416],\n       ...,\n       [0.51960263, 0.42971241, 0.43482412, 0.42584272, 0.41826583],\n       [0.44638841, 0.45169849, 0.44236854, 0.43449762, 0.46068183],\n       [0.45167629, 0.4423468 , 0.43447626, 0.46065919, 0.44647657]])>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Normalizing Volume feature\n",
    "tf.linalg.normalize(nvda[:, :, 4], axis=1)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 13:00:08.024798: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at reduction_ops_common.h:147 : INVALID_ARGUMENT: Invalid reduction dimension (2 for input with 2 dimension(s)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Sum_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (2 for input with 2 dimension(s) [Op:Sum]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Full logic\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Subset and create normalized tensors\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m norm_candlestick \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnormalize(nvda[:, :, \u001B[38;5;241m4\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      5\u001B[0m norm_volume \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnormalize(nvda[:, :, \u001B[38;5;241m4\u001B[39m])[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/trading-system/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/trading-system/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__Sum_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (2 for input with 2 dimension(s) [Op:Sum]"
     ]
    }
   ],
   "source": [
    "# Full logic\n",
    "\n",
    "# Subset and create normalized tensors\n",
    "norm_candlestick = tf.linalg.normalize(nvda[:, :, 4], axis=2)[0]\n",
    "norm_volume = tf.linalg.normalize(nvda[:, :, 4])[0]\n",
    "\n",
    "# Stitch back together in correct shape w/ stock splits and dividends"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shuffling tensors of rank 3\n",
    "\n",
    "For the non-temporal approach learning can be improved by creating a non-sequential dataset, however how this has been structured means that I need to shuffle two tensors in the same way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64) tf.Tensor([b'a' b'b' b'c' b'd' b'e'], shape=(5,), dtype=string)\n",
      "(<tf.Tensor: shape=(5,), dtype=int64, numpy=array([3, 4, 1, 0, 2])>,) tf.Tensor([b'd' b'e' b'b' b'a' b'c'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(np.arange(5))\n",
    "y = tf.convert_to_tensor(['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "indices = tf.range(start=0, limit=tf.shape(x)[0])\n",
    "shuffled_indices = tf.random.shuffle(indices)\n",
    "\n",
    "shuffled_x = tf.gather(x, shuffled_indices),\n",
    "shuffled_y = tf.gather(y, shuffled_indices)\n",
    "\n",
    "print(x, y)\n",
    "print(shuffled_x, shuffled_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to function and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def shuffle_tensors(X, y, seed=None):\n",
    "    assert tf.shape(X)[0] == tf.shape(y)[0], 'X and y MUST be the same length'\n",
    "    shuffled_indices = tf.random.shuffle(\n",
    "        tf.range(start=0, limit=tf.shape(X)[0]),\n",
    "        seed=seed\n",
    "    )\n",
    "    shuffled_x = tf.gather(X, shuffled_indices, axis=0)\n",
    "    shuffled_y = tf.gather(y, shuffled_indices, axis=0)\n",
    "    return shuffled_x, shuffled_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n array([[5, 6],\n        [3, 4],\n        [1, 2]], dtype=int32)>,\n <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n array([[15, 16],\n        [13, 14],\n        [11, 12]], dtype=int32)>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = tf.Variable(\n",
    "    [\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 6]\n",
    "    ])\n",
    "\n",
    "test_2 = tf.Variable(\n",
    "    [\n",
    "        [11, 12],\n",
    "        [13, 14],\n",
    "        [15, 16]\n",
    "    ]\n",
    ")\n",
    "\n",
    "shuffle_tensors(test_1, test_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/dataPreparation/shuffleTensors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/dataPreparation/shuffleTensors.py\n",
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def shuffle_tensors(X, y, seed=None):\n",
    "    '''\n",
    "\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    '''\n",
    "    assert tf.shape(X)[0] == tf.shape(y)[0], 'X and y MUST be the same length'\n",
    "    shuffled_indices = tf.random.shuffle(\n",
    "        tf.range(start=0, limit=tf.shape(X)[0]),\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    shuffled_X = tf.gather(X, shuffled_indices, axis=0)\n",
    "    shuffled_y = tf.gather(y, shuffled_indices, axis=0)\n",
    "\n",
    "    return shuffled_X, shuffled_y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
